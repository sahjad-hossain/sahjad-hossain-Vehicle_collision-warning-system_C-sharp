// ------------------------------------------------------------------------------
//  <auto-generated>
//     This code was generated by BASELABS Create.
//
//     Changes to this file may cause incorrect behavior and will be lost if
//     the code is regenerated.
// </auto-generated>
// ------------------------------------------------------------------------------
using  System;
using  System.Collections.Generic ;
using System.Reflection;
using System.CodeDom.Compiler;
using System.Threading.Tasks;
using Baselabs.Collections;
using Baselabs.Statistics.Distributions;
using Baselabs.Statistics.Filters;
using Baselabs.Statistics.Models;
using Baselabs.Statistics.Spaces;
using Baselabs.Statistics.Tracking.Spaces;
using Baselabs.Statistics.Tracking.Models;
using Baselabs.Statistics.Tracking.Distributions;
using Baselabs.Statistics.Tracking.Tracks;
using Baselabs.ThirdParty.LapackBlas;
using Baselabs.Statistics.Models.MeasurementModels;
using Baselabs.Statistics.Models.SystemModels;
using Baselabs.Statistics.Tracking.Collections;
using Baselabs.Statistics.Tracking.Association;
using Baselabs.Statistics.Tracking.Gating;

namespace DataFusion
{
    #region Data Fusion configuration

    using StateSpace = CVComponentsSpace;
    using Track = GaussianTrack<CVComponentsSpace>;

    #endregion Data Fusion configuration

    /// <summary>
    /// Provides methods and algorithms to track multiple objects using data fusion.
    /// </summary>
    [GeneratedCode("BASELABS Create Data Fusion Code Generator", "1.0.0.0")]
    public partial class DataFusion1 : IDisposable
    {
        #region Data fusion parameters
        
        #region System properties
        
        public System.Double SigmaAccelerationX
        {
            get;
            set;
        }
        
        public System.Double SigmaAccelerationY
        {
            get;
            set;
        }
        
        #endregion System properties
        
        #region RadarSensor measurement model
        
        public System.Double SensorPositionX
        {
            get;
            set;
        }
        
        public System.Double SensorPositionY
        {
            get;
            set;
        }
        
        public System.Double SensorRotationZ
        {
            get;
            set;
        }
        
        public System.Double SigmaAzimuth
        {
            get;
            set;
        }
        
        public System.Double SigmaRange
        {
            get;
            set;
        }
        
        public System.Double SigmaRangeRate
        {
            get;
            set;
        }
        
        #endregion RadarSensor measurement model
        
        #region RadarSensor detection model
        
        public System.Double DetectionAngleMax
        {
            get;
            set;
        }
        
        public System.Double DetectionAngleMin
        {
            get;
            set;
        }
        
        public System.Double DetectionRangeMax
        {
            get;
            set;
        }
        
        public System.Double DetectionRangeMin
        {
            get;
            set;
        }
        
        #endregion RadarSensor detection model
        
        #region RadarSensor track proposer
        
        public System.Double SigmaVx
        {
            get;
            set;
        }
        
        public System.Double SigmaVy
        {
            get;
            set;
        }
        
        public System.Double SigmaX
        {
            get;
            set;
        }
        
        public System.Double SigmaY
        {
            get;
            set;
        }
        
        public System.Double InitialExistenceProbability
        {
            get;
            set;
        }
        
        #endregion RadarSensor track proposer
        
        #region CameraSensor measurement model
        
        public System.Double SigmaColumn
        {
            get;
            set;
        }
        
        public System.Double SigmaRow
        {
            get;
            set;
        }
        
        #endregion CameraSensor measurement model
        
        #region Track removers
        
        public System.Double MinimumExistenceProbability
        {
            get;
            set;
        }
        
        #endregion Track removers

        #endregion Data fusion parameters

        #region Filters and states

        private static readonly StateSpace StateIndices = Space.GetIndices<StateSpace>();
        private EgoMotionFilter _egoMotionFilter;

        [Obfuscation(Feature = "BASELABSCode/ValueRequired", StripAfterObfuscation = false)]
        IList<Track> _tracks;

        private bool _disposed = false;

        #endregion Filters and states

        #region Initialization

        /// <summary>
        /// Creates a new <see cref="DataFusion1" /> instance.
        /// </summary>
        public DataFusion1()
        {
            InitializeDataFusionParameters();
            Reset();
            Processing = ProcessingKind.MaximumSpeed;
            Initialize();
        }

        /// <summary>
        /// If implemented, this method is called during the initialization of the class.
        /// </summary>
        partial void Initialize();

        /// <summary>
        /// Resets all states.
        /// </summary>
        public void Reset()
        {
            _egoMotionFilter = new EgoMotionFilter();
            _tracks = TracksFactory.CreateInstance<Track>();
            LastUpdateTime = null;
        }

        private void InitializeDataFusionParameters()
        {
            this.SigmaAccelerationX = 2D;
            
            this.SigmaAccelerationY = 2D;
            
            this.SensorPositionX = 3.55D;
            
            this.SensorPositionY = 0D;
            
            this.SensorRotationZ = 0D;
            
            this.SigmaAzimuth = 0.01D;
            
            this.SigmaRange = 1.2D;
            
            this.SigmaRangeRate = 0.45D;
            
            this.DetectionAngleMax = 0.16D;
            
            this.DetectionAngleMin = -0.16D;
            
            this.DetectionRangeMax = 200D;
            
            this.DetectionRangeMin = 1D;
            
            this.SigmaVx = 1.4D;
            
            this.SigmaVy = 1.2D;
            
            this.SigmaX = 1D;
            
            this.SigmaY = 1D;
            
            this.InitialExistenceProbability = 0.8D;
            
            this.SigmaColumn = 6D;
            
            this.SigmaRow = 6D;
            
            this.MinimumExistenceProbability = 0.1D;
            
        }

        public void Dispose()
        {
            Dispose(true);
            GC.SuppressFinalize(this);
        }

        protected virtual void Dispose(bool disposing)
        {
            if (!_disposed)
            {
                if (disposing)
                {
                    Cleanup();
                }

                // release unmanaged resources here
            }

            _disposed = true;
        }

        /// <summary>
        /// If implemented, this method is called during the cleanup of managed class resources.
        /// </summary>
        partial void Cleanup();

        #endregion Initialization

        #region Egomotion incorporation

        /// <summary>
        /// Incorporates the yaw rate of the ego vehicle.
        /// </summary>
        /// <param name="time">The time of the yaw rate measurement.</param>
        /// <param name="yawRate">The yaw rate of the ego vehicle in radians per second.</param>
        /// <exception cref="System.ArgumentException">The time of the measurement is not a Coordinated Universal Time (UTC).</exception>
        public void ProcessYawRate(DateTime time, YawRateSpace yawRate)
        {
            if (time.Kind != DateTimeKind.Utc)
            {
                throw new ArgumentException("The time of the measurement is not a Coordinated Universal Time (UTC).");
            }

            OnYawRateProcessing(time, yawRate.W);

            _egoMotionFilter.Filter(time, yawRate);

            OnYawRateProcessed();
        }

        /// <summary>
        /// Incorporates the velocity of the ego vehicle.
        /// </summary>
        /// <param name="time">The time of the velocity measurement.</param>
        /// <param name="velocity">The velocity of the ego vehicle in meters per second.</param>
        /// <exception cref="System.ArgumentException">The time of the measurement is not a Coordinated Universal Time (UTC).</exception>
        public void ProcessVelocity(DateTime time, VelocitySpace velocity)
        {
            if (time.Kind != DateTimeKind.Utc)
            {
                throw new ArgumentException("The time of the measurement is not a Coordinated Universal Time (UTC).");
            }

            OnVelocityProcessing(time, velocity.V);

            _egoMotionFilter.Filter(time, velocity);

            OnVelocityProcessed();
        }

        /// <summary>
        /// Represents the method that will handle the start of a signal processing.
        /// </summary>
        public delegate void SignalProcessingHandler(DateTime time, double value);

        /// <summary>
        /// Represents the method that will handle the end of a signal processing.
        /// </summary>
        public delegate void SignalProcessedHandler();

        /// <summary>
        /// Occurs when the processing of a yaw rate measurement starts.
        /// </summary>
        public event SignalProcessingHandler YawRateProcessing;

        /// <param name="yawrate">The yaw rate of the ego vehicle in rad/s.</param>
        [System.Diagnostics.Conditional("DATAFUSIONEVENTS")]
        protected void OnYawRateProcessing(DateTime time, double yawrate)
        {
            var handler = YawRateProcessing;

            if (handler != null)
            {
                handler(time, yawrate);
            }
        }

        /// <summary>
        /// Occurs when the processing of a yaw rate measurement has been finished.
        /// </summary>
        public event SignalProcessedHandler YawRateProcessed;

        [System.Diagnostics.Conditional("DATAFUSIONEVENTS")]
        protected void OnYawRateProcessed()
        {
            var handler = YawRateProcessed;

            if (handler != null)
            {
                handler();
            }
        }

        /// <summary>
        /// Occurs when the processing of a velocity measurement starts.
        /// </summary>
        public event SignalProcessingHandler VelocityProcessing;

        /// <param name="velocity">The velocity of the ego vehicle in m/s.</param>
        [System.Diagnostics.Conditional("DATAFUSIONEVENTS")]
        protected void OnVelocityProcessing(DateTime time, double velocity)
        {
            var handler = VelocityProcessing;

            if (handler != null)
            {
                handler(time, velocity);
            }
        }

        /// <summary>
        /// Occurs when the processing of a velocity measurement has been finished.
        /// </summary>
        public event SignalProcessedHandler VelocityProcessed;

        [System.Diagnostics.Conditional("DATAFUSIONEVENTS")]
        protected void OnVelocityProcessed()
        {
            var handler = VelocityProcessed;

            if (handler != null)
            {
                handler();
            }
        }

        #endregion Egomotion incorporation

        #region Tracks

        /// <summary>
        /// Tries to get the tracks at the specified time.
        /// </summary>
        /// <param name="time">The time to predict the tracks to.</param>
        /// <param name="tracks">The tracks at the specified time stamp.</param>
        /// <returns>
        /// <c>True</c> if the ego motion is stable, the <see cref="LastUpdateTime" /> is not <c>null</c> and the given
        /// <paramref name="time" /> is greater or equal to the <see cref="LastUpdateTime" /> of the tracks, otherwise <c>False</c>.
        /// </returns>
        /// <remarks>
        /// This method predicts all tracks to the given timestamp. The current state can be retrieved by using <see cref="LastUpdateTime" />
        /// as the time parameter.
        /// The out parameter <paramref name="tracks" /> contains the tracks if the method returns <c>True</c>, otherwise it is set to <c>null</c>.
        /// </remarks>
        public bool GetTracks(DateTime time, out IEnumerable<Track> tracks)
        {
            if (!LastUpdateTime.HasValue)
            {
                tracks = default(IList<Track>);
                return false;
            }

            if ((time - LastUpdateTime.Value).TotalMilliseconds < 0)
            {
                throw new ArgumentOutOfRangeException("time",
                    @"The time to predict the track list to is in the past. Time difference should not be negative.");
            }

            var egoMotionState = _egoMotionFilter.PredictX(time);

            if (ReferenceEquals(egoMotionState, null) || !_egoMotionFilter.IsStable)
            {
                tracks = default(IList<Track>);
                return false;
            }

            var deltaT = time - LastUpdateTime.Value;
            var tracksList = TracksFactory.CreateInstance<Track>();
            tracks = tracksList;

            if (deltaT == TimeSpan.Zero)
            {
                foreach (var track in _tracks)
                {
                    tracksList.Add(
                    new Track(
                    new Gaussian<StateSpace>(track.State.Expectation, track.State.Covariance),
                    new Existence(track.Existence),
                    track));
                }
            }
            else
            {
                var systemModel = new DataFusion.CVVectorialModel()
                {
                    SigmaAccelerationX = this.SigmaAccelerationX,
                    SigmaAccelerationY = this.SigmaAccelerationY,
                };

                var persistenceModel = new PersistenceModel(0.001)
                {
                    TimeCondition = deltaT
                };

                var egoMotionCompensation = new EgoMotionCompensation<StateSpace, CTRVSpace>();

                // deep copy
                foreach (var track in _tracks)
                {
                    var egoMotionCompensatedState = egoMotionCompensation
                        .Marginalize<StateSpace, EgoMotionCompensation<StateSpace, CTRVSpace>, StateSpace, CTRVSpace>(
                            track.State, egoMotionState).ToGaussian();

                    var predictedState = UKF
                        .PredictState(deltaT, egoMotionCompensatedState, systemModel.NoiseCovariance, systemModel)
                        .ToGaussian();

                    var predictedExistence = new Existence(BayesFilter.Predict(track.Existence, persistenceModel));

                    tracksList.Add(new Track(predictedState, predictedExistence, track));
                }
            }

            OnTracksRequested(time, tracks);

            return true;
        }

        /// <summary>
        /// Represents the method that will handle requested tracks.
        /// </summary>
        public delegate void TracksHandler(DateTime time, IEnumerable<Track> tracks);

        /// <summary>
        /// Occurs when tracks are requested by the <see cref="GetTracks"/> method.
        /// </summary>
        public event TracksHandler TracksRequested;

        [System.Diagnostics.Conditional("DATAFUSIONEVENTS")]
        protected void OnTracksRequested(DateTime time, IEnumerable<Track> tracks)
        {
            var handler = TracksRequested;

            if (handler != null)
            {
                handler(time, tracks);
            }
        }

        #endregion Tracks

        #region Properties

        /// <summary>
        /// Gets the timestamp of the last tracks update.
        /// </summary>
        /// <remarks>
        /// This property provides <c>null</c> if tracks were never updated.
        /// </remarks>
        public DateTime? LastUpdateTime { get; private set; }

        #endregion Properties

        #region RadarSensor

        /// <summary>
        /// Incorporates 'RadarSensor' detections.
        /// </summary>
        /// <param name="time">The time of the detections.</param>
        /// <param name="measurements">The 'RadarSensor' measurements.</param>
        /// <exception cref="System.ArgumentException">The time of the measurement is not a Coordinated Universal Time (UTC).</exception>
        public void ProcessMeasurements0(DateTime time, IEnumerable<RadarSpace> measurements)
        {
            if (Environment.ProcessorCount > 1 && DegreeOfParallelism != 1)
            {
                ParallelProcessMeasurements0(time, measurements);
            }
            else
            {
                SequentialProcessMeasurements0(time, measurements);
            }
        }

        /// <summary>
        /// Incorporates 'RadarSensor' detections in parallel.
        /// </summary>
        /// <param name="time">The time of the detections.</param>
        /// <param name="measurements">The 'RadarSensor' measurements.</param>
        /// <exception cref="System.ArgumentException">The time of the measurement is not a Coordinated Universal Time (UTC).</exception>
        private void ParallelProcessMeasurements0(DateTime time, IEnumerable<RadarSpace> measurements)
        {
            if (!_egoMotionFilter.IsStable)
            {
                return;
            }

            if (time.Kind != DateTimeKind.Utc)
            {
                throw new ArgumentException(
                    "The time of the measurement is not a Coordinated Universal Time (UTC).");
            }

            Gaussian<CTRVSpace> egoMotionState = _egoMotionFilter.PredictXAndReset(time);

            if (!LastUpdateTime.HasValue)
            {
                LastUpdateTime = time;
            }

            if ((time - LastUpdateTime.Value).TotalMilliseconds < 0)
            {
                throw new ArgumentOutOfRangeException("time",
                    @"The time of the new measurement is in the past. Time difference should not be negative.");
            }

            _egoVelocity = egoMotionState.Expectation.V;
            _egoYawrate = egoMotionState.Expectation.W;

            OnProcessing0(time, measurements);

            var predictedStates = new SigmaPoints<StateSpace>[_tracks.Count];
            var predictedMeasurements = new SigmaPoints<RadarSpace>[_tracks.Count];
            var likelihoodIntegrals = new Gaussian<RadarSpace>[_tracks.Count];
            var predictedExistences = new Existence[_tracks.Count];

            #if DATAFUSIONEVENTS
            var predictions = new Prediction<StateSpace, RadarSpace>[_tracks.Count];
            #endif

            var predictionResults = new PredictionResult<StateSpace, RadarSpace>[_tracks.Count];
            int count = _tracks.Count;
            Parallel.For(0, count,
                new ParallelOptions()
                {
                    MaxDegreeOfParallelism = DegreeOfParallelism
                },
                (index, state) =>
                {
                    var track = _tracks[index];

                    var predictedTrack = Predict0(time, track, egoMotionState);

                    predictedExistences[index] = predictedTrack.PredictedExistence;
                    predictedStates[index] = predictedTrack.PredictedState;
                    predictedMeasurements[index] = predictedTrack.PredictedMeasurement;
                    likelihoodIntegrals[index] = predictedTrack.LikelihoodIntegral;
                    predictionResults[index] = predictedTrack;
                    #if DATAFUSIONEVENTS
                    predictions[index] = new Prediction<StateSpace, RadarSpace>
                    {
                        Time = time,
                        TrackId = predictedTrack.Track.ID,
                        State = predictedTrack.PredictedState.ToGaussian(),
                        Existence = predictedTrack.PredictedExistence,
                        Measurement = predictedTrack.LikelihoodIntegral
                    };
                    #endif
                });

            #if DATAFUSIONEVENTS
            OnPredicted0(predictions);
            #endif

            var association = MeasurementAssociation0(measurements, likelihoodIntegrals, predictedExistences);
            var updatedTracks = new List<Track>();
            #if DATAFUSIONEVENTS
            var associations = new Association<RadarSpace>[_tracks.Count];
            #endif

            Parallel.For(0, count,
                new ParallelOptions()
                {
                    MaxDegreeOfParallelism = DegreeOfParallelism
                },
                (index, state) =>
                {
                    var predictionResult = predictionResults[index];

                    // Get the associated measurements for the track. As the actual algorithm has been done during the creation of the
                    // MeasurementAssociation object, the access is thread-safe and needs no lock.
                    var associatedMeasurements = association.GetAssociatedObjects(index);

                    var result = Update0(predictionResult, associatedMeasurements);

                    #if DATAFUSIONEVENTS
                    associations[index] = result.Association;
                    #endif

                    var updatedTrack = result.Track;
                    if (updatedTrack != null)
                    {
                        lock (updatedTracks)
                        {
                            updatedTracks.Add(updatedTrack);
                        }
                    }
                });

            #if DATAFUSIONEVENTS
            OnAssociated0(associations);
            #endif

            Parallel.ForEach(association.GetNotAssociatedObjects(),
                new ParallelOptions()
                {
                    MaxDegreeOfParallelism = DegreeOfParallelism
                },
                (notAssociatedMeasurement, state) =>
                {
                    var result = ProposeNewTracks0(egoMotionState, notAssociatedMeasurement);
                    lock (updatedTracks)
                    {
                        updatedTracks.AddRange(result.NewTracks);
                    }
            });

            _tracks = updatedTracks;
            LastUpdateTime = time;

            OnProcessed0();
        }

        /// <summary>
        /// Incorporates 'RadarSensor' detections sequentially.
        /// </summary>
        /// <param name="time">The time of the detections.</param>
        /// <param name="measurements">The 'RadarSensor' measurements.</param>
        /// <exception cref="System.ArgumentException">The time of the measurement is not a Coordinated Universal Time (UTC).</exception>
        private void SequentialProcessMeasurements0(DateTime time, IEnumerable<RadarSpace> measurements)
        {
            if (!_egoMotionFilter.IsStable)
            {
                return;
            }

            if (time.Kind != DateTimeKind.Utc)
            {
                throw new ArgumentException(
                    "The time of the measurement is not a Coordinated Universal Time (UTC).");
            }

            Gaussian<CTRVSpace> egoMotionState = _egoMotionFilter.PredictXAndReset(time);

            if (!LastUpdateTime.HasValue)
            {
                LastUpdateTime = time;
            }

            if ((time - LastUpdateTime.Value).TotalMilliseconds < 0)
            {
                throw new ArgumentOutOfRangeException("time",
                    @"The time of the new measurement is in the past. Time difference should not be negative.");
            }

            _egoVelocity = egoMotionState.Expectation.V;
            _egoYawrate = egoMotionState.Expectation.W;

            OnProcessing0(time, measurements);

            // Create arrays for all intermediate distributions of the tracks.
            StaticIPDATrackingCollectionsFactoryProvider factoryProvider = new StaticIPDATrackingCollectionsFactoryProvider(100, 50);
            var predictedStates = factoryProvider.TrackListFactory.CreateInstance<SigmaPoints<StateSpace>>();
            var predictedMeasurements = factoryProvider.TrackListFactory.CreateInstance<SigmaPoints<RadarSpace>>();
            var likelihoodIntegrals = factoryProvider.TrackListFactory.CreateInstance<Gaussian<RadarSpace>>();
            var predictedExistences = factoryProvider.TrackListFactory.CreateInstance<Existence>();
            var predictedTracks = factoryProvider.TrackListFactory.CreateInstance<PredictionResult<StateSpace, RadarSpace>>();

            #if DATAFUSIONEVENTS
            var predictions = new List<Prediction<StateSpace, RadarSpace>>();
            #endif

            foreach (var track in _tracks)
            {
                var predictedTrack = Predict0(time, track, egoMotionState);

                predictedStates.Add(predictedTrack.PredictedState);
                predictedExistences.Add(predictedTrack.PredictedExistence);
                predictedMeasurements.Add(predictedTrack.PredictedMeasurement);
                likelihoodIntegrals.Add(predictedTrack.LikelihoodIntegral);
                predictedTracks.Add(predictedTrack);

                #if DATAFUSIONEVENTS
                predictions.Add(new Prediction<StateSpace, RadarSpace>
                {
                    Time = time,
                    TrackId = predictedTrack.Track.ID,
                    State = predictedTrack.PredictedState.ToGaussian(),
                    Existence = predictedTrack.PredictedExistence,
                    Measurement = predictedTrack.LikelihoodIntegral
                });
                #endif
            }

            #if DATAFUSIONEVENTS
            OnPredicted0(predictions);
            #endif

            var association = MeasurementAssociation0(measurements, likelihoodIntegrals, predictedExistences);
            var updatedTracks = factoryProvider.TrackListFactory.CreateInstance<Track>();

            #if DATAFUSIONEVENTS
            var associations = new List<Association<RadarSpace>>();
            #endif

            int index = 0;
            foreach (var predictedTrack in predictedTracks)
            {
                // Get the associated measurements for the track. As the actual algorithm has been done during the creation of the
                // MeasurementAssociation object, the access is thread-safe and needs no lock.
                var associatedMeasurements = association.GetAssociatedObjects(index++);

                var result = Update0(predictedTrack, associatedMeasurements);

                #if DATAFUSIONEVENTS
                associations.Add(result.Association);
                #endif

                var updatedTrack = result.Track;
                if (updatedTrack != null)
                {
                    updatedTracks.Add(updatedTrack);
                }
            }

            #if DATAFUSIONEVENTS
            OnAssociated0(associations);
            #endif

            foreach (var notAssociatedMeasurement in association.GetNotAssociatedObjects())
            {
                var result = ProposeNewTracks0(egoMotionState, notAssociatedMeasurement);
                foreach (var newTrack in result.NewTracks)
                {
                    updatedTracks.Add(newTrack);
                }
            }

            _tracks = updatedTracks;
            LastUpdateTime = time;

            OnProcessed0();
        }

        /// <summary>
        ///  Predicts a track for the 'RadarSensor'.
        /// </summary>
        /// <param name="time">The time.</param>
        /// <param name="track">The track.</param>
        /// <param name="egoMotionState">The state of the ego motion.</param>
        /// <returns>The prediction.</returns>
        private PredictionResult<StateSpace, RadarSpace> Predict0(DateTime time, Track track, Gaussian<CTRVSpace> egoMotionState)
        {
            var systemModel = new DataFusion.CVVectorialModel()
            {
                SigmaAccelerationX = this.SigmaAccelerationX,
                SigmaAccelerationY = this.SigmaAccelerationY,
            };

            var persistenceModel = new PersistenceModel(0.001)
            {
                TimeCondition = time - LastUpdateTime.Value
            };

            var egoMotionCompensation = new EgoMotionCompensation<StateSpace, CTRVSpace>();

            // Do the ego-motion compensation of the track state. This is done by solving the Chapman-Kolmogorov Integral:
            // p(x_compensated) = ∫∫ p(x_compensated | x_uncompensated, x_egomotion) p(x_uncompensated) p(x_egomotion) dx_uncompensated dx_egomotion
            var egoMotionCompensatedState = egoMotionCompensation.Marginalize<StateSpace, EgoMotionCompensation<StateSpace, CTRVSpace>, StateSpace, CTRVSpace>(
                track.State,
                egoMotionState).ToGaussian();

            // Predict the track state to the current time. The result is represented by sigma points, it is
            // p(x_k|Z_{k-1}) = ∫ p(x_k|x_{k-1}) p(x_{k-1}|Z_{k-1}) dx_{k-1}
            var predictedState = UKF.PredictState(
                time - LastUpdateTime.Value,
                egoMotionCompensatedState,
                systemModel.NoiseCovariance,
                systemModel);

            // Predict the existence probability. With every prediction it approaches a little bit to 0.5.
            var predictedExistence =
                new Existence(BayesFilter.Predict(track.Existence, persistenceModel));

            var measurementModel = new DataFusion.RadarMeasurementModel()
            {
                EgoVelocity = GetEgoVelocity(),
                EgoYawRate = GetEgoYawrate(),
                SensorPositionX = this.SensorPositionX,
                SensorPositionY = this.SensorPositionY,
                SensorRotationZ = this.SensorRotationZ,
                SigmaAzimuth = this.SigmaAzimuth,
                SigmaRange = this.SigmaRange,
                SigmaRangeRate = this.SigmaRangeRate,
            };

            // Predict the measurement of the track. The result are sigma points.
            var predictedMeasurement = UKF.PredictMeasurement<StateSpace, RadarSpace, DataFusion.RadarMeasurementModel>(
                predictedState,
                    measurementModel);

            // Calculate the track likelihood conditioned on all previous measurements: p(z_k|Z_{k-1}).
            // It is called "likelihood integral" because it is calculated using the Chapman-Kolmogorov integral:
            // p(z_k|Z_{k-1}) = ∫ p(z_k|x_k) p(x_k|Z_{k-1}) dx_k
            // Since we use a UKF, this is actually the predicted measurement. But it needs to be evaluable, therefore, we have to calculate the Gaussian from the sigma points.
            var likelihoodIntegral = predictedMeasurement.ToGaussian();

            return new PredictionResult<StateSpace, RadarSpace>()
            {
                PredictedState = predictedState,
                PredictedExistence = predictedExistence,
                PredictedMeasurement = predictedMeasurement,
                LikelihoodIntegral = likelihoodIntegral,
                Track = track
            };
        }

        /// <summary>
        /// Associates 'RadarSensor' measurements to the tracks.
        /// </summary>
        /// <param name="measurements">The measurements.</param>
        /// <param name="likelihoodIntegrals">The likelihood integrals.</param>
        /// <param name="predictedExistences">The predicted existences.</param>
        /// <returns>The association.</returns>
        private MeasurementAssociation<Gaussian<RadarSpace>, RadarSpace> MeasurementAssociation0(IEnumerable<RadarSpace> measurements, IList<Gaussian<RadarSpace>> likelihoodIntegrals, IList<Existence> predictedExistences)
        {
            StaticIPDATrackingCollectionsFactoryProvider factoryProvider = new StaticIPDATrackingCollectionsFactoryProvider(
                100,
                50);

            var associationAlgorithm = new MultipleLocalNearestNeighbor(factoryProvider);

            // Define the gate by the gate probability.
            var gate = new ProbabilityGate<RadarSpace>(0.99);

            // Perform the association of the measurements to the tracks. When the instance is returned, the
            // actual association is already finished.
            var association = MeasurementAssociation.Create(
                likelihoodIntegrals,
                predictedExistences,
                measurements,
                associationAlgorithm,
                gate,
                factoryProvider);

            return association;
        }

        /// <summary>
        /// Updates a track using the associated measurements.
        /// </summary>
        /// <param name="predictionResult">The result from the prediction step.</param>
        /// <param name="associatedMeasurements">The measurements associated with this predicted track.</param>
        /// <returns>The result includes the updated track or null if the track has been removed by any of the track removers.</returns>
        /// <remarks></remarks>
        private UpdateResult<RadarSpace> Update0(PredictionResult<StateSpace, RadarSpace> predictionResult, IEnumerable<RadarSpace> associatedMeasurements)
        {
            var result = new UpdateResult<RadarSpace>()
            {
                Track = null,
                #if DATAFUSIONEVENTS
                Association = null
                #endif
            };

            var detectionModel = new DataFusion.RadarDetectionModel()
            {
                DetectionAngleMax = this.DetectionAngleMax,
                DetectionAngleMin = this.DetectionAngleMin,
                DetectionRangeMax = this.DetectionRangeMax,
                DetectionRangeMin = this.DetectionRangeMin,
            };
            detectionModel.GateProbability = 0.99;

            // Create random samples from the track likelihood for the prediction of the detection cardinality likelihood.
            var listFactory = new StaticListFactory(100);
            var sampledPredictedMeasurement = new SampleSet<CVComponentsSpace>(
                predictionResult.PredictedState.ToGaussian().Draw(100),
                listFactory);

            // Marginalize the cardinality likelihood over the predicted measurement, i.e. solve the integral
            // p(#z|Z_{k-1}) = ∫ p(#z | z) p(z|Z_{k-1}) dz
            var measurementCardinalityLikelihood =
                new MarginalizedEvaluable<
                    CardinalitySpace,
                    DataFusion.RadarDetectionModel,
                    CVComponentsSpace,
                    SampleSet<CVComponentsSpace>>(
                    detectionModel,
                    sampledPredictedMeasurement);

            StaticIPDATrackingCollectionsFactoryProvider factoryProvider = new StaticIPDATrackingCollectionsFactoryProvider(100, 50);

            // Create the true positives hypotheses. Like for the measurement association, the algorithm is performed in the constructor.
            var hypothesisGenerator = IPDA.Create(
                predictionResult.LikelihoodIntegral,
                predictionResult.PredictedExistence,
                measurementCardinalityLikelihood,
                associatedMeasurements,
                0.0001,
                factoryProvider);
            var associationHypotheses = hypothesisGenerator.GetHypotheses();

            #if DATAFUSIONEVENTS
            result.Association = new Association<RadarSpace>()
            {
                TrackId = predictionResult.Track.ID,
                Hypotheses = associationHypotheses
            };
            #endif

            var existenceConditionedElementsLikelihood = hypothesisGenerator.GetElementsLikelihood();
            var mixedState = new GaussianMixture<StateSpace>(
                associationHypotheses.Count,
                factoryProvider.HypothesisListFactory);

            foreach (var hypothesis in associationHypotheses)
            {
                // IPDA considers at maximum one element as true positive
                var truePositiveMeasurement = FirstOrDefault(hypothesis.Elements);

                if (truePositiveMeasurement == null)
                {
                    mixedState.Add(predictionResult.PredictedState.ToGaussian(), hypothesis.Weight);
                }
                else
                {
                    mixedState.Add(
                        UKF.Update(
                            predictionResult.PredictedState,
                            predictionResult.PredictedMeasurement,
                            truePositiveMeasurement),
                        hypothesis.Weight);
                }
            }

            var updatedState = mixedState.ToGaussian();

            // Update the track existence using the likelihood of the set of associated measurements conditioned on the existence.
            var updatedExistence = BayesFilter.Update(
                predictionResult.PredictedExistence,
                existenceConditionedElementsLikelihood);

            var updatedTrack = new Track(updatedState, new Existence(updatedExistence), predictionResult.Track);

            var shouldRemoveTrack = false;

            if(!shouldRemoveTrack)
            {
                var trackRemover = new DataFusion.ClutterRemover()
                {
                    MinimumExistenceProbability = this.MinimumExistenceProbability,
                };

                if (trackRemover.ShouldRemove(updatedTrack))
                {
                    shouldRemoveTrack = true;
                }
            }

            if (!shouldRemoveTrack)
            {
                result.Track = updatedTrack;
            }
            return result;
        }

        /// <summary>
        /// Proposes new track(s) from a 'RadarSensor' measurement.
        /// </summary>
        /// <param name="egoMotionState">The state of the ego motion.</param>
        /// <param name="notAssociatedMeasurement">The measurement.</param>
        /// <returns>The list of new tracks.</returns>
        private PropositionResult ProposeNewTracks0(Gaussian<CTRVSpace> egoMotionState, RadarSpace notAssociatedMeasurement)
        {
            var trackProposer = new DataFusion.RadarTrackProposer()
            {
                EgoVelocity = GetEgoVelocity(),
                EgoYawRate = GetEgoYawrate(),
                SensorPositionX = this.SensorPositionX,
                SensorPositionY = this.SensorPositionY,
                SensorRotationZ = this.SensorRotationZ,
                SigmaVx = this.SigmaVx,
                SigmaVy = this.SigmaVy,
                SigmaX = this.SigmaX,
                SigmaY = this.SigmaY,
                InitialExistenceProbability = this.InitialExistenceProbability,
            };

            return new PropositionResult() {
                NewTracks = trackProposer.CreateTracks(notAssociatedMeasurement)
            };
        }

        /// <summary>
        /// Represents the method that will handle the start of 'RadarSensor' processing.
        /// </summary>
        public delegate void ProcessingHandler0(DateTime time, IEnumerable<RadarSpace> measurements);

        /// <summary>
        /// Occurs when 'RadarSensor' processing starts.
        /// </summary>
        public event ProcessingHandler0 Processing0;

        [System.Diagnostics.Conditional("DATAFUSIONEVENTS")]
        protected void OnProcessing0(DateTime time, IEnumerable<RadarSpace> measurements)
        {
            var handler = Processing0;

            if (handler != null)
            {
                handler(time, measurements);
            }
        }

        /// <summary>
        /// Represents the method that will handle the end of 'RadarSensor' processing.
        /// </summary>
        public delegate void ProcessedHandler0();

        /// <summary>
        /// Occurs when 'RadarSensor' processing has been finished.
        /// </summary>
        public event ProcessedHandler0 Processed0;

        [System.Diagnostics.Conditional("DATAFUSIONEVENTS")]
        protected void OnProcessed0()
        {
            var handler = Processed0;

            if (handler != null)
            {
                handler();
            }
        }

        /// <summary>
        /// Represents the method that will handle the predictions for the 'RadarSensor'.
        /// </summary>
        public delegate void PredictedHandler0(IEnumerable<Prediction<StateSpace, RadarSpace>> predictions);

        /// <summary>
        /// Occurs when new predictions for the 'RadarSensor' are available.
        /// </summary>
        public event PredictedHandler0 Predicted0;

        [System.Diagnostics.Conditional("DATAFUSIONEVENTS")]
        protected void OnPredicted0(IEnumerable<Prediction<StateSpace, RadarSpace>> predictions)
        {
            var handler = Predicted0;

            if (handler != null)
            {
                handler(predictions);
            }
        }

        /// <summary>
        /// Represents the method that will handle measurement-to-track associations for the 'RadarSensor'.
        /// </summary>
        public delegate void AssociatedHandler0(IEnumerable<Association<RadarSpace>> associations);

        /// <summary>
        /// Occurs when new measurement-to-track associations for the 'RadarSensor' are available.
        /// </summary>
        public event AssociatedHandler0 Associated0;

        [System.Diagnostics.Conditional("DATAFUSIONEVENTS")]
        protected void OnAssociated0(IEnumerable<Association<RadarSpace>> associations)
        {
            var handler = Associated0;

            if (handler != null)
            {
                handler(associations);
            }
        }

        #endregion RadarSensor

        #region CameraSensor

        /// <summary>
        /// Incorporates 'CameraSensor' detections.
        /// </summary>
        /// <param name="time">The time of the detections.</param>
        /// <param name="measurements">The 'CameraSensor' measurements.</param>
        /// <exception cref="System.ArgumentException">The time of the measurement is not a Coordinated Universal Time (UTC).</exception>
        public void ProcessMeasurements1(DateTime time, IEnumerable<CameraSpace> measurements)
        {
            if (Environment.ProcessorCount > 1 && DegreeOfParallelism != 1)
            {
                ParallelProcessMeasurements1(time, measurements);
            }
            else
            {
                SequentialProcessMeasurements1(time, measurements);
            }
        }

        /// <summary>
        /// Incorporates 'CameraSensor' detections in parallel.
        /// </summary>
        /// <param name="time">The time of the detections.</param>
        /// <param name="measurements">The 'CameraSensor' measurements.</param>
        /// <exception cref="System.ArgumentException">The time of the measurement is not a Coordinated Universal Time (UTC).</exception>
        private void ParallelProcessMeasurements1(DateTime time, IEnumerable<CameraSpace> measurements)
        {
            if (!_egoMotionFilter.IsStable)
            {
                return;
            }

            if (time.Kind != DateTimeKind.Utc)
            {
                throw new ArgumentException(
                    "The time of the measurement is not a Coordinated Universal Time (UTC).");
            }

            Gaussian<CTRVSpace> egoMotionState = _egoMotionFilter.PredictXAndReset(time);

            if (!LastUpdateTime.HasValue)
            {
                LastUpdateTime = time;
            }

            if ((time - LastUpdateTime.Value).TotalMilliseconds < 0)
            {
                throw new ArgumentOutOfRangeException("time",
                    @"The time of the new measurement is in the past. Time difference should not be negative.");
            }

            _egoVelocity = egoMotionState.Expectation.V;
            _egoYawrate = egoMotionState.Expectation.W;

            OnProcessing1(time, measurements);

            var predictedStates = new SigmaPoints<StateSpace>[_tracks.Count];
            var predictedMeasurements = new SigmaPoints<CameraSpace>[_tracks.Count];
            var likelihoodIntegrals = new Gaussian<CameraSpace>[_tracks.Count];
            var predictedExistences = new Existence[_tracks.Count];

            #if DATAFUSIONEVENTS
            var predictions = new Prediction<StateSpace, CameraSpace>[_tracks.Count];
            #endif

            var predictionResults = new PredictionResult<StateSpace, CameraSpace>[_tracks.Count];
            int count = _tracks.Count;
            Parallel.For(0, count,
                new ParallelOptions()
                {
                    MaxDegreeOfParallelism = DegreeOfParallelism
                },
                (index, state) =>
                {
                    var track = _tracks[index];

                    var predictedTrack = Predict1(time, track, egoMotionState);

                    predictedExistences[index] = predictedTrack.PredictedExistence;
                    predictedStates[index] = predictedTrack.PredictedState;
                    predictedMeasurements[index] = predictedTrack.PredictedMeasurement;
                    likelihoodIntegrals[index] = predictedTrack.LikelihoodIntegral;
                    predictionResults[index] = predictedTrack;
                    #if DATAFUSIONEVENTS
                    predictions[index] = new Prediction<StateSpace, CameraSpace>
                    {
                        Time = time,
                        TrackId = predictedTrack.Track.ID,
                        State = predictedTrack.PredictedState.ToGaussian(),
                        Existence = predictedTrack.PredictedExistence,
                        Measurement = predictedTrack.LikelihoodIntegral
                    };
                    #endif
                });

            #if DATAFUSIONEVENTS
            OnPredicted1(predictions);
            #endif

            var association = MeasurementAssociation1(measurements, likelihoodIntegrals, predictedExistences);
            var updatedTracks = new List<Track>();
            #if DATAFUSIONEVENTS
            var associations = new Association<CameraSpace>[_tracks.Count];
            #endif

            Parallel.For(0, count,
                new ParallelOptions()
                {
                    MaxDegreeOfParallelism = DegreeOfParallelism
                },
                (index, state) =>
                {
                    var predictionResult = predictionResults[index];

                    // Get the associated measurements for the track. As the actual algorithm has been done during the creation of the
                    // MeasurementAssociation object, the access is thread-safe and needs no lock.
                    var associatedMeasurements = association.GetAssociatedObjects(index);

                    var result = Update1(predictionResult, associatedMeasurements);

                    #if DATAFUSIONEVENTS
                    associations[index] = result.Association;
                    #endif

                    var updatedTrack = result.Track;
                    if (updatedTrack != null)
                    {
                        lock (updatedTracks)
                        {
                            updatedTracks.Add(updatedTrack);
                        }
                    }
                });

            #if DATAFUSIONEVENTS
            OnAssociated1(associations);
            #endif

            Parallel.ForEach(association.GetNotAssociatedObjects(),
                new ParallelOptions()
                {
                    MaxDegreeOfParallelism = DegreeOfParallelism
                },
                (notAssociatedMeasurement, state) =>
                {
                    var result = ProposeNewTracks1(egoMotionState, notAssociatedMeasurement);
                    lock (updatedTracks)
                    {
                        updatedTracks.AddRange(result.NewTracks);
                    }
            });

            _tracks = updatedTracks;
            LastUpdateTime = time;

            OnProcessed1();
        }

        /// <summary>
        /// Incorporates 'CameraSensor' detections sequentially.
        /// </summary>
        /// <param name="time">The time of the detections.</param>
        /// <param name="measurements">The 'CameraSensor' measurements.</param>
        /// <exception cref="System.ArgumentException">The time of the measurement is not a Coordinated Universal Time (UTC).</exception>
        private void SequentialProcessMeasurements1(DateTime time, IEnumerable<CameraSpace> measurements)
        {
            if (!_egoMotionFilter.IsStable)
            {
                return;
            }

            if (time.Kind != DateTimeKind.Utc)
            {
                throw new ArgumentException(
                    "The time of the measurement is not a Coordinated Universal Time (UTC).");
            }

            Gaussian<CTRVSpace> egoMotionState = _egoMotionFilter.PredictXAndReset(time);

            if (!LastUpdateTime.HasValue)
            {
                LastUpdateTime = time;
            }

            if ((time - LastUpdateTime.Value).TotalMilliseconds < 0)
            {
                throw new ArgumentOutOfRangeException("time",
                    @"The time of the new measurement is in the past. Time difference should not be negative.");
            }

            _egoVelocity = egoMotionState.Expectation.V;
            _egoYawrate = egoMotionState.Expectation.W;

            OnProcessing1(time, measurements);

            // Create arrays for all intermediate distributions of the tracks.
            StaticIPDATrackingCollectionsFactoryProvider factoryProvider = new StaticIPDATrackingCollectionsFactoryProvider(100, 50);
            var predictedStates = factoryProvider.TrackListFactory.CreateInstance<SigmaPoints<StateSpace>>();
            var predictedMeasurements = factoryProvider.TrackListFactory.CreateInstance<SigmaPoints<CameraSpace>>();
            var likelihoodIntegrals = factoryProvider.TrackListFactory.CreateInstance<Gaussian<CameraSpace>>();
            var predictedExistences = factoryProvider.TrackListFactory.CreateInstance<Existence>();
            var predictedTracks = factoryProvider.TrackListFactory.CreateInstance<PredictionResult<StateSpace, CameraSpace>>();

            #if DATAFUSIONEVENTS
            var predictions = new List<Prediction<StateSpace, CameraSpace>>();
            #endif

            foreach (var track in _tracks)
            {
                var predictedTrack = Predict1(time, track, egoMotionState);

                predictedStates.Add(predictedTrack.PredictedState);
                predictedExistences.Add(predictedTrack.PredictedExistence);
                predictedMeasurements.Add(predictedTrack.PredictedMeasurement);
                likelihoodIntegrals.Add(predictedTrack.LikelihoodIntegral);
                predictedTracks.Add(predictedTrack);

                #if DATAFUSIONEVENTS
                predictions.Add(new Prediction<StateSpace, CameraSpace>
                {
                    Time = time,
                    TrackId = predictedTrack.Track.ID,
                    State = predictedTrack.PredictedState.ToGaussian(),
                    Existence = predictedTrack.PredictedExistence,
                    Measurement = predictedTrack.LikelihoodIntegral
                });
                #endif
            }

            #if DATAFUSIONEVENTS
            OnPredicted1(predictions);
            #endif

            var association = MeasurementAssociation1(measurements, likelihoodIntegrals, predictedExistences);
            var updatedTracks = factoryProvider.TrackListFactory.CreateInstance<Track>();

            #if DATAFUSIONEVENTS
            var associations = new List<Association<CameraSpace>>();
            #endif

            int index = 0;
            foreach (var predictedTrack in predictedTracks)
            {
                // Get the associated measurements for the track. As the actual algorithm has been done during the creation of the
                // MeasurementAssociation object, the access is thread-safe and needs no lock.
                var associatedMeasurements = association.GetAssociatedObjects(index++);

                var result = Update1(predictedTrack, associatedMeasurements);

                #if DATAFUSIONEVENTS
                associations.Add(result.Association);
                #endif

                var updatedTrack = result.Track;
                if (updatedTrack != null)
                {
                    updatedTracks.Add(updatedTrack);
                }
            }

            #if DATAFUSIONEVENTS
            OnAssociated1(associations);
            #endif

            foreach (var notAssociatedMeasurement in association.GetNotAssociatedObjects())
            {
                var result = ProposeNewTracks1(egoMotionState, notAssociatedMeasurement);
                foreach (var newTrack in result.NewTracks)
                {
                    updatedTracks.Add(newTrack);
                }
            }

            _tracks = updatedTracks;
            LastUpdateTime = time;

            OnProcessed1();
        }

        /// <summary>
        ///  Predicts a track for the 'CameraSensor'.
        /// </summary>
        /// <param name="time">The time.</param>
        /// <param name="track">The track.</param>
        /// <param name="egoMotionState">The state of the ego motion.</param>
        /// <returns>The prediction.</returns>
        private PredictionResult<StateSpace, CameraSpace> Predict1(DateTime time, Track track, Gaussian<CTRVSpace> egoMotionState)
        {
            var systemModel = new DataFusion.CVVectorialModel()
            {
                SigmaAccelerationX = this.SigmaAccelerationX,
                SigmaAccelerationY = this.SigmaAccelerationY,
            };

            var persistenceModel = new PersistenceModel(0.001)
            {
                TimeCondition = time - LastUpdateTime.Value
            };

            var egoMotionCompensation = new EgoMotionCompensation<StateSpace, CTRVSpace>();

            // Do the ego-motion compensation of the track state. This is done by solving the Chapman-Kolmogorov Integral:
            // p(x_compensated) = ∫∫ p(x_compensated | x_uncompensated, x_egomotion) p(x_uncompensated) p(x_egomotion) dx_uncompensated dx_egomotion
            var egoMotionCompensatedState = egoMotionCompensation.Marginalize<StateSpace, EgoMotionCompensation<StateSpace, CTRVSpace>, StateSpace, CTRVSpace>(
                track.State,
                egoMotionState).ToGaussian();

            // Predict the track state to the current time. The result is represented by sigma points, it is
            // p(x_k|Z_{k-1}) = ∫ p(x_k|x_{k-1}) p(x_{k-1}|Z_{k-1}) dx_{k-1}
            var predictedState = UKF.PredictState(
                time - LastUpdateTime.Value,
                egoMotionCompensatedState,
                systemModel.NoiseCovariance,
                systemModel);

            // Predict the existence probability. With every prediction it approaches a little bit to 0.5.
            var predictedExistence =
                new Existence(BayesFilter.Predict(track.Existence, persistenceModel));

            var measurementModel = new DataFusion.CameraMeasurementModel()
            {
                SigmaColumn = this.SigmaColumn,
                SigmaRow = this.SigmaRow,
            };

            // Predict the measurement of the track. The result are sigma points.
            var predictedMeasurement = UKF.PredictMeasurement<StateSpace, CameraSpace, DataFusion.CameraMeasurementModel>(
                predictedState,
                    measurementModel);

            // Calculate the track likelihood conditioned on all previous measurements: p(z_k|Z_{k-1}).
            // It is called "likelihood integral" because it is calculated using the Chapman-Kolmogorov integral:
            // p(z_k|Z_{k-1}) = ∫ p(z_k|x_k) p(x_k|Z_{k-1}) dx_k
            // Since we use a UKF, this is actually the predicted measurement. But it needs to be evaluable, therefore, we have to calculate the Gaussian from the sigma points.
            var likelihoodIntegral = predictedMeasurement.ToGaussian();

            return new PredictionResult<StateSpace, CameraSpace>()
            {
                PredictedState = predictedState,
                PredictedExistence = predictedExistence,
                PredictedMeasurement = predictedMeasurement,
                LikelihoodIntegral = likelihoodIntegral,
                Track = track
            };
        }

        /// <summary>
        /// Associates 'CameraSensor' measurements to the tracks.
        /// </summary>
        /// <param name="measurements">The measurements.</param>
        /// <param name="likelihoodIntegrals">The likelihood integrals.</param>
        /// <param name="predictedExistences">The predicted existences.</param>
        /// <returns>The association.</returns>
        private MeasurementAssociation<Gaussian<CameraSpace>, CameraSpace> MeasurementAssociation1(IEnumerable<CameraSpace> measurements, IList<Gaussian<CameraSpace>> likelihoodIntegrals, IList<Existence> predictedExistences)
        {
            StaticIPDATrackingCollectionsFactoryProvider factoryProvider = new StaticIPDATrackingCollectionsFactoryProvider(
                100,
                50);

            var associationAlgorithm = new MultipleLocalNearestNeighbor(factoryProvider);

            // Define the gate by the gate probability.
            var gate = new ProbabilityGate<CameraSpace>(0.99);

            // Perform the association of the measurements to the tracks. When the instance is returned, the
            // actual association is already finished.
            var association = MeasurementAssociation.Create(
                likelihoodIntegrals,
                predictedExistences,
                measurements,
                associationAlgorithm,
                gate,
                factoryProvider);

            return association;
        }

        /// <summary>
        /// Updates a track using the associated measurements.
        /// </summary>
        /// <param name="predictionResult">The result from the prediction step.</param>
        /// <param name="associatedMeasurements">The measurements associated with this predicted track.</param>
        /// <returns>The result includes the updated track or null if the track has been removed by any of the track removers.</returns>
        /// <remarks></remarks>
        private UpdateResult<CameraSpace> Update1(PredictionResult<StateSpace, CameraSpace> predictionResult, IEnumerable<CameraSpace> associatedMeasurements)
        {
            var result = new UpdateResult<CameraSpace>()
            {
                Track = null,
                #if DATAFUSIONEVENTS
                Association = null
                #endif
            };

            var detectionModel = new DataFusion.CameraDetectionModel()
            {
                DetectionAngleMax = this.DetectionAngleMax,
                DetectionAngleMin = this.DetectionAngleMin,
                DetectionRangeMax = this.DetectionRangeMax,
                DetectionRangeMin = this.DetectionRangeMin,
            };
            detectionModel.GateProbability = 0.99;

            // Create random samples from the track likelihood for the prediction of the detection cardinality likelihood.
            var listFactory = new StaticListFactory(100);
            var sampledPredictedMeasurement = new SampleSet<CVComponentsSpace>(
                predictionResult.PredictedState.ToGaussian().Draw(100),
                listFactory);

            // Marginalize the cardinality likelihood over the predicted measurement, i.e. solve the integral
            // p(#z|Z_{k-1}) = ∫ p(#z | z) p(z|Z_{k-1}) dz
            var measurementCardinalityLikelihood =
                new MarginalizedEvaluable<
                    CardinalitySpace,
                    DataFusion.CameraDetectionModel,
                    CVComponentsSpace,
                    SampleSet<CVComponentsSpace>>(
                    detectionModel,
                    sampledPredictedMeasurement);

            StaticIPDATrackingCollectionsFactoryProvider factoryProvider = new StaticIPDATrackingCollectionsFactoryProvider(100, 50);

            // Create the true positives hypotheses. Like for the measurement association, the algorithm is performed in the constructor.
            var hypothesisGenerator = IPDA.Create(
                predictionResult.LikelihoodIntegral,
                predictionResult.PredictedExistence,
                measurementCardinalityLikelihood,
                associatedMeasurements,
                0.0001,
                factoryProvider);
            var associationHypotheses = hypothesisGenerator.GetHypotheses();

            #if DATAFUSIONEVENTS
            result.Association = new Association<CameraSpace>()
            {
                TrackId = predictionResult.Track.ID,
                Hypotheses = associationHypotheses
            };
            #endif

            var existenceConditionedElementsLikelihood = hypothesisGenerator.GetElementsLikelihood();
            var mixedState = new GaussianMixture<StateSpace>(
                associationHypotheses.Count,
                factoryProvider.HypothesisListFactory);

            foreach (var hypothesis in associationHypotheses)
            {
                // IPDA considers at maximum one element as true positive
                var truePositiveMeasurement = FirstOrDefault(hypothesis.Elements);

                if (truePositiveMeasurement == null)
                {
                    mixedState.Add(predictionResult.PredictedState.ToGaussian(), hypothesis.Weight);
                }
                else
                {
                    mixedState.Add(
                        UKF.Update(
                            predictionResult.PredictedState,
                            predictionResult.PredictedMeasurement,
                            truePositiveMeasurement),
                        hypothesis.Weight);
                }
            }

            var updatedState = mixedState.ToGaussian();

            // Update the track existence using the likelihood of the set of associated measurements conditioned on the existence.
            var updatedExistence = BayesFilter.Update(
                predictionResult.PredictedExistence,
                existenceConditionedElementsLikelihood);

            var updatedTrack = new Track(updatedState, new Existence(updatedExistence), predictionResult.Track);

            var shouldRemoveTrack = false;

            if(!shouldRemoveTrack)
            {
                var trackRemover = new DataFusion.ClutterRemover()
                {
                    MinimumExistenceProbability = this.MinimumExistenceProbability,
                };

                if (trackRemover.ShouldRemove(updatedTrack))
                {
                    shouldRemoveTrack = true;
                }
            }

            if (!shouldRemoveTrack)
            {
                result.Track = updatedTrack;
            }
            return result;
        }

        /// <summary>
        /// Proposes new track(s) from a 'CameraSensor' measurement.
        /// </summary>
        /// <param name="egoMotionState">The state of the ego motion.</param>
        /// <param name="notAssociatedMeasurement">The measurement.</param>
        /// <returns>The list of new tracks.</returns>
        private PropositionResult ProposeNewTracks1(Gaussian<CTRVSpace> egoMotionState, CameraSpace notAssociatedMeasurement)
        {
            var trackProposer = new DataFusion.CameraTrackProposer()
            {
                EgoVelocity = GetEgoVelocity(),
            };

            return new PropositionResult() {
                NewTracks = trackProposer.CreateTracks(notAssociatedMeasurement)
            };
        }

        /// <summary>
        /// Represents the method that will handle the start of 'CameraSensor' processing.
        /// </summary>
        public delegate void ProcessingHandler1(DateTime time, IEnumerable<CameraSpace> measurements);

        /// <summary>
        /// Occurs when 'CameraSensor' processing starts.
        /// </summary>
        public event ProcessingHandler1 Processing1;

        [System.Diagnostics.Conditional("DATAFUSIONEVENTS")]
        protected void OnProcessing1(DateTime time, IEnumerable<CameraSpace> measurements)
        {
            var handler = Processing1;

            if (handler != null)
            {
                handler(time, measurements);
            }
        }

        /// <summary>
        /// Represents the method that will handle the end of 'CameraSensor' processing.
        /// </summary>
        public delegate void ProcessedHandler1();

        /// <summary>
        /// Occurs when 'CameraSensor' processing has been finished.
        /// </summary>
        public event ProcessedHandler1 Processed1;

        [System.Diagnostics.Conditional("DATAFUSIONEVENTS")]
        protected void OnProcessed1()
        {
            var handler = Processed1;

            if (handler != null)
            {
                handler();
            }
        }

        /// <summary>
        /// Represents the method that will handle the predictions for the 'CameraSensor'.
        /// </summary>
        public delegate void PredictedHandler1(IEnumerable<Prediction<StateSpace, CameraSpace>> predictions);

        /// <summary>
        /// Occurs when new predictions for the 'CameraSensor' are available.
        /// </summary>
        public event PredictedHandler1 Predicted1;

        [System.Diagnostics.Conditional("DATAFUSIONEVENTS")]
        protected void OnPredicted1(IEnumerable<Prediction<StateSpace, CameraSpace>> predictions)
        {
            var handler = Predicted1;

            if (handler != null)
            {
                handler(predictions);
            }
        }

        /// <summary>
        /// Represents the method that will handle measurement-to-track associations for the 'CameraSensor'.
        /// </summary>
        public delegate void AssociatedHandler1(IEnumerable<Association<CameraSpace>> associations);

        /// <summary>
        /// Occurs when new measurement-to-track associations for the 'CameraSensor' are available.
        /// </summary>
        public event AssociatedHandler1 Associated1;

        [System.Diagnostics.Conditional("DATAFUSIONEVENTS")]
        protected void OnAssociated1(IEnumerable<Association<CameraSpace>> associations)
        {
            var handler = Associated1;

            if (handler != null)
            {
                handler(associations);
            }
        }

        #endregion CameraSensor

        #region Helper functions and classes

        private double _egoVelocity;

        private double GetEgoVelocity()
        {
            return _egoVelocity;
        }

        private double _egoYawrate;

        private double GetEgoYawrate()
        {
            return _egoYawrate;
        }

        /// <summary>
        /// Provides predicted elements.
        /// </summary>
        /// <typeparam name="TStateSpace">The state space.</typeparam>
        /// <typeparam name="TMeasurementSpace">The measurement space.</typeparam>
        public class Prediction<TStateSpace, TMeasurementSpace>
            where TStateSpace : Space, new()
            where TMeasurementSpace : Space, new()
        {
            /// <summary>
            /// Gets or sets the time of the prediction.
            /// </summary>
            public DateTime Time { get; set; }

            /// <summary>
            /// Gets or sets the id of the track.
            /// </summary>
            public ulong TrackId { get; set; }

            /// <summary>
            /// Gets or sets the predicted state.
            /// </summary>
            public Gaussian<TStateSpace> State { get; set; }

            /// <summary>
            /// Gets or sets the predicted measurement or likelihood integral.
            /// </summary>
            public Gaussian<TMeasurementSpace> Measurement { get; set; }

            /// <summary>
            /// Gets or sets the predicted existence.
            /// </summary>
            public Existence Existence { get; set; }
        }

        /// <summary>
        /// Provides the hypotheses of the associated measurements.
        /// </summary>
        /// <typeparam name="TAssociationSpace">The association space.</typeparam>
        public class Association<TAssociationSpace>
            where TAssociationSpace : Space
        {
            /// <summary>
            /// Gets or sets the id of the track.
            /// </summary>
            public ulong TrackId { get; set; }

            /// <summary>
            /// Gets or sets the hypotheses of the measurements that are associated to the track.
            /// </summary>
            public IEnumerable<TruePositivesHypothesis<TAssociationSpace>> Hypotheses { get; set; }
        }

        /// <summary>
        /// Returns the first element of a sequence, or a default value if the sequence contains no elements.
        /// </summary>
        /// <typeparam name="T">The type of the elements of <paramref name="source"/>.</typeparam>
        /// <param name="source">The <see cref="IEnumerable{T}"/> to return the first element of.</param>
        /// <returns>
        /// The first element of <paramref name="source"/> or the default value of <typeparamref name="T"/>
        /// if <paramref name="source"/> is empty.
        /// </returns>
        private T FirstOrDefault<T>(IEnumerable<T> source)
        {
            using (var enumerator = source.GetEnumerator())
            {
                if (enumerator.MoveNext())
                {
                    return enumerator.Current;
                }

                return default(T);
            }
        }

        private static IListFactory TracksFactory
        {
            get
            {
                return new StaticListFactory(100);
            }
        }

        /// <summary>
        /// The result distribution of
        /// <see cref="Conditional.Marginalize{TSpace,TConditional,TConditionSpace,TCondition}(TConditional,TCondition)" />.
        /// </summary>
        /// <typeparam name="TSpace">The type of the space.</typeparam>
        /// <typeparam name="TConditional">The type of the conditional distribution.</typeparam>
        /// <typeparam name="TConditionSpace">The type of the condition space.</typeparam>
        /// <typeparam name="TCondition">The type of the condition.</typeparam>
        internal class MarginalizedEvaluable<TSpace, TConditional, TConditionSpace, TCondition> :
            IEvaluable<TSpace>
            where TSpace : Space, new()
            where TConditionSpace : Space
            where TConditional : class, IConditional<TConditionSpace>, IEvaluable<TSpace>
            where TCondition : IEvaluable<TConditionSpace>, IEnumerable<SampleProbabilityPair<TConditionSpace>>
        {
            readonly TConditional _conditionalDistribution;
            readonly TCondition _condition;

            public MarginalizedEvaluable(TConditional conditionalDistribution, TCondition condition)
            {
                _conditionalDistribution = conditionalDistribution;
                _condition = condition;
            }

            public double Evaluate(TSpace sample)
            {
                double probability = 0.0;

                foreach (var pair in _condition)
                {
                    _conditionalDistribution.Condition = pair.Sample;
                    probability += _conditionalDistribution.Evaluate(sample) * pair.Probability;
                }

                return probability;
            }
        }

        /// <summary>
        /// Represents the result of the prediction step.
        /// </summary>
        /// <typeparam name="TStateSpace">The state space.</typeparam>
        /// <typeparam name="TMeasurementSpace">The measurement space.</typeparam>
        private class PredictionResult<TStateSpace, TMeasurementSpace>
            where TStateSpace : Space, new()
            where TMeasurementSpace : Space, new()
        {
            public SigmaPoints<TStateSpace> PredictedState { get; set; }

            public SigmaPoints<TMeasurementSpace> PredictedMeasurement { get; set; }

            public Gaussian<TMeasurementSpace> LikelihoodIntegral { get; set; }

            public Existence PredictedExistence { get; set; }

            public Track Track { get; set; }
        }

        /// <summary>
        /// Represents the result from the update step.
        /// </summary>
        /// <typeparam name="TMeasurementSpace">The measurement space.</typeparam>
        private class UpdateResult<TMeasurementSpace>
            where TMeasurementSpace : Space, new()
        {
            public Track Track {get; set;}

            #if DATAFUSIONEVENTS
            public Association<TMeasurementSpace> Association {get; set;}
            #endif
        }

        /// <summary>
        /// Represents the result from the track proposer.
        /// </summary>
        private class PropositionResult
        {
            public IEnumerable<Track> NewTracks {get; set;}
        }

        #endregion Helper functions and classes

        #region Processing

        /// <summary>
        /// Defines the kind of processing for the data fusion algorithm.
        /// </summary>
        public enum ProcessingKind
        {
            /// <summary>
            /// The data fusion algorithm processes tracks at maximum speed. This setting leverages parallel execution on multi-core CPUs.
            /// </summary>
            MaximumSpeed,
            /// <summary>
            /// The data fusion algorithm processes tracks for full reproducibility during debugging.
            /// </summary>
            Debugging
        };

        ///<summary>
        /// The kind of processing. Set to <see cref="T:ProcessingKind.MaximumSpeed" /> to leverage parallel execution on multi-core CPUs. Set to <see cref="T:ProcessingKind.Debugging" /> for maximum debugging reproducibility.
        /// </summary>
        public ProcessingKind Processing { get; set; }

        private int _tasksMax = Environment.ProcessorCount;

        ///<summary>
        /// Gets or sets the maximum number of concurrent tasks.
        /// </summary>
        /// <remarks>The property affects the number of concurrent operations run when <see cref="Processing" /> is set to <see cref="T:ProcessingKind.MaximumSpeed" />.
        /// The value is not used when <see cref="Processing" /> is set to <see cref="T:ProcessingKind.Debugging" />.
        /// A positive property value limits the number of concurrent operations to the set value.
        /// If it is -1, there is no limit on the number of concurrently running operations.
        /// The default value is set to <see cref="Environment.ProcessorCount"/>.</remarks>
        /// <exception cref="System.ArgumentOutOfRangeException">The property is being set to zero or to a value that is less than -1.</exception>
        public int TasksMax
        {
            get { return _tasksMax; }
            set
            {
                if (value==0 || value < -1)
                {
                    throw new ArgumentOutOfRangeException("TasksMax",value,"Specified argument was out of the range of valid values. The value must not be zero or smaller than -1.");
                }
                _tasksMax = value;
            }
        }

        /// <summary>
        /// Gets the number of concurrent tasks.
        /// </summary>
        private int DegreeOfParallelism
        {
            get
            {
                return Processing == ProcessingKind.MaximumSpeed ? TasksMax : 1;
            }
        }

        #endregion Processing

        #region Egomotion filter

        /// <summary>
        /// Provides an ego motion filter which determines the position and heading difference
        /// using the velocity and yaw rate.
        /// </summary>
        private class EgoMotionFilter
        {
            // For details on the chosen parameters see
            // Schubert et al.: Empirical Evaluation of Vehicular Models for Ego Motion Estimation,
            // Intelligent Vehicles Symposium 2011, Baden-Baden, Germany

            /// <summary>
            /// The standard deviation of the velocity process noise [m/s].
            /// </summary>
            const double ProcessSigmaV = 1.5;

            /// <summary>
            /// The standard deviation of the yaw rate process noise [rad/s].
            /// </summary>
            const double ProcessSigmaW = 0.29;

            /// <summary>
            /// The standard deviation of the velocity measurement noise [m/s].
            /// </summary>
            const double MeasurementSigmaV = 4.07e-2;

            /// <summary>
            /// The standard deviation of the yaw rate measurement noise [rad/s].
            /// </summary>
            const double MeasurementSigmaW = 2.53e-3;

            readonly CTRVModel<CTRVSpace, CTRVErrorSpace> _systemModel =
                new CTRVModel<CTRVSpace, CTRVErrorSpace>(
                new PositiveDefiniteMatrix<CTRVErrorSpace>(ProcessSigmaV * ProcessSigmaV, ProcessSigmaW * ProcessSigmaW));

            readonly VelocityMeasurementModel<VelocitySpace, CTRVSpace> _velocityMeasurementModel =
                new VelocityMeasurementModel<VelocitySpace, CTRVSpace>(
                new PositiveDefiniteMatrix<VelocitySpace>(MeasurementSigmaV * MeasurementSigmaV));

            readonly YawRateMeasurementModel<YawRateSpace, CTRVSpace> _yawRateMeasurementModel =
                new YawRateMeasurementModel<YawRateSpace, CTRVSpace>(
                new PositiveDefiniteMatrix<YawRateSpace>(MeasurementSigmaW * MeasurementSigmaW));

            bool _isVelocityFiltered;
            bool _isYawRateFiltered;
            DateTime? _lastCorrectionTime;
            Gaussian<CTRVSpace> _state;

            /// <summary>
            /// Creates a new instance of the <see cref="EgoMotionFilter"/> class.
            /// </summary>
            public EgoMotionFilter()
            {
                Reset();
            }

            /// <summary>
            /// Gets a value indicating a stable filter state.
            /// </summary>
            public bool IsStable
            {
                get { return _isVelocityFiltered && _isYawRateFiltered; }
            }

            /// <summary>
            /// Incorporates a velocity measurement.
            /// </summary>
            /// <param name="time">The time of the measurement.</param>
            /// <param name="velocity">The velocity measurement.</param>
            public void Filter(DateTime time, VelocitySpace velocity)
            {
                if (!_lastCorrectionTime.HasValue)
                {
                    _lastCorrectionTime = time;
                }

                if ((time - _lastCorrectionTime.Value).TotalMilliseconds < 0)
                {
                    throw new ArgumentOutOfRangeException("time",
                        @"The time of the new measurement is in the past. Time difference should not be negative.");
                }

                SigmaPoints<CTRVSpace> sigmaPointsX = UKF.PredictState(
                    time - _lastCorrectionTime.Value, _state, _systemModel.NoiseCovariance, _systemModel);
                SigmaPoints<VelocitySpace> sigmaPointsY =
                    UKF.PredictMeasurement<CTRVSpace, VelocitySpace, VelocityMeasurementModel<VelocitySpace, CTRVSpace>>
                    (sigmaPointsX, _velocityMeasurementModel);
                _state = UKF.Update(sigmaPointsX, sigmaPointsY, velocity);

                _lastCorrectionTime = time;
                _isVelocityFiltered = true;
            }

            /// <summary>
            /// Incorporates a yaw rate measurement.
            /// </summary>
            /// <param name="time">The time of the measurement.</param>
            /// <param name="yawRate">The yaw rate measurement.</param>
            public void Filter(DateTime time, YawRateSpace yawRate)
            {
                if (!_lastCorrectionTime.HasValue)
                {
                    _lastCorrectionTime = time;
                }

                if ((time - _lastCorrectionTime.Value).TotalMilliseconds < 0)
                {
                    throw new ArgumentOutOfRangeException("time",
                        @"The time of the new measurement is in the past. Time difference should not be negative.");
                }

                SigmaPoints<CTRVSpace> sigmaPointsX = UKF.PredictState(
                    time - _lastCorrectionTime.Value, _state, _systemModel.NoiseCovariance, _systemModel);
                SigmaPoints<YawRateSpace> sigmaPointsY =
                    UKF.PredictMeasurement<CTRVSpace, YawRateSpace, YawRateMeasurementModel<YawRateSpace, CTRVSpace>>(
                        sigmaPointsX, _yawRateMeasurementModel);
                _state = UKF.Update(sigmaPointsX, sigmaPointsY, yawRate);

                _lastCorrectionTime = time;
                _isYawRateFiltered = true;
            }

            /// <summary>
            /// Predicts the state to the given time.
            /// </summary>
            /// <param name="time">The time to which the state is predicted to.</param>
            /// <returns>The predicted state.</returns>
            public Gaussian<CTRVSpace> PredictX(DateTime time)
            {
                if (!IsStable || !_lastCorrectionTime.HasValue)
                {
                    throw new InvalidOperationException("The estimation is not stable.");
                }

                return
                    UKF.PredictState(time - _lastCorrectionTime.Value, _state, _systemModel.NoiseCovariance, _systemModel)
                    .ToGaussian();
                }

            /// <summary>
            /// Predicts the state to the given time and resets the filter.
            /// </summary>
            /// <param name="time">The time to which the state is predicted to.</param>
            /// <returns>The predicted state.</returns>
            public Gaussian<CTRVSpace> PredictXAndReset(DateTime time)
            {
                Gaussian<CTRVSpace> result = PredictX(time);

                _lastCorrectionTime = time;
                ResetPosition();

                return result;
            }

            /// <summary>
            /// Resets the filter.
            /// </summary>
            public void Reset()
            {
                _lastCorrectionTime = null;
                _isVelocityFiltered = false;
                _isYawRateFiltered = false;

                _state = new Gaussian<CTRVSpace>();

                _state.Covariance[0, 0] = 1.0e-3;
                _state.Covariance[1, 1] = 1.0e-3;
                _state.Covariance[2, 2] = 1.0e-3;
                _state.Covariance[3, 3] = 1.0e3;
                _state.Covariance[4, 4] = 1.0e3;
            }

            void ResetPosition()
            {
                _state.Expectation.X = 0;
                _state.Expectation.Y = 0;
                _state.Expectation.G = 0;

                _state.Covariance[0, 0] = 0.0001;
                _state.Covariance[0, 1] = 0;
                _state.Covariance[0, 2] = 0;
                _state.Covariance[0, 3] = 0;
                _state.Covariance[0, 4] = 0;

                _state.Covariance[1, 0] = 0;
                _state.Covariance[1, 1] = 0.0001;
                _state.Covariance[1, 2] = 0;
                _state.Covariance[1, 3] = 0;
                _state.Covariance[1, 4] = 0;

                _state.Covariance[2, 0] = 0;
                _state.Covariance[2, 1] = 0;
                _state.Covariance[2, 2] = 1.0e-6;
                _state.Covariance[2, 3] = 0;
                _state.Covariance[2, 4] = 0;

                _state.Covariance[3, 0] = 0;
                _state.Covariance[3, 1] = 0;
                _state.Covariance[3, 2] = 0;

                _state.Covariance[4, 0] = 0;
                _state.Covariance[4, 1] = 0;
                _state.Covariance[4, 2] = 0;
            }
        }

        #endregion Egomotion filter
    }
}
